{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich import traceback\n",
    "\n",
    "traceback.install()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"possible_cases_4.txt\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "# examples\n",
    "# Sequence: [(0, 1), (0, 2), (0, 3), (1, 2), (1, 2, 3)]\n",
    "# Coverage history: [{(0, 1)}, {(0, 2)}, {(0, 3)}, {(1, 2)}, {(2, 3), (1, 3)}]\n",
    "\n",
    "# Sequence: [(0, 1), (0, 2), (0, 3), (1, 2), (0, 1, 2, 3)]\n",
    "# Coverage history: [{(0, 1)}, {(0, 2)}, {(0, 3)}, {(1, 2)}, {(2, 3), (1, 3)}]\n",
    "\n",
    "# Sequence: [(0, 1), (0, 2), (0, 3), (1, 3), (1, 2, 3)]\n",
    "# Coverage history: [{(0, 1)}, {(0, 2)}, {(0, 3)}, {(1, 3)}, {(2, 3), (1, 2)}]\n",
    "\n",
    "sequence_list = []\n",
    "coverage_list = []\n",
    "for line in lines:\n",
    "    line = line.strip()\n",
    "    if line.startswith(\"Sequence\"):\n",
    "        sequence = eval(line.split(\":\")[1])\n",
    "        sequence_list.append(sequence)\n",
    "    if line.startswith(\"Coverage history\"):\n",
    "        coverage = eval(line.split(\":\")[1])\n",
    "        coverage_list.append(coverage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(sequence_list))\n",
    "print(len(coverage_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- There are eleven possible 4-motifs in total (allowing isolated nodes):\n",
    "    - {0}(0-1) An empty graph\n",
    "    - {1}(1-1) A single edge\n",
    "    - {2}(2-1) Two disconnected edges\n",
    "    - {3}(2-2) Two connected edges (i.e., wedge or open triangle)\n",
    "    - {4}(3-1) A 3-path\n",
    "    - {5}(3-2) A triangle\n",
    "    - {6}(3-3) A 3-star\n",
    "    - {7}(4-1) A 4-cycle\n",
    "    - {8}(4-2) A triangle + an edge\n",
    "    - {9}(5-1) Two triangles sharing a common edge\n",
    "    - {10}(6-1) A 4-clique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert each \"coverage\" to an accumulated coverage\n",
    "accumulated_coverage_list = []\n",
    "for coverage in coverage_list:\n",
    "    accumulated_coverage = [frozenset()]\n",
    "    for cov in coverage:\n",
    "        accumulated_coverage.append(accumulated_coverage[-1] | cov)\n",
    "    accumulated_coverage_list.append(accumulated_coverage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from itertools import combinations, chain\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda:1\")\n",
    "\n",
    "all_pairs = list(combinations(range(4), 2))  # in total 6 pairs\n",
    "all_pairs = [frozenset(pair) for pair in all_pairs]\n",
    "\n",
    "# https://stackoverflow.com/questions/1482308\n",
    "def powerset(iterable):\n",
    "    \"powerset([1,2,3]) --> () (1,) (2,) (3,) (1,2) (1,3) (2,3) (1,2,3)\"\n",
    "    s = list(iterable)\n",
    "    return chain.from_iterable(combinations(s, r) for r in range(len(s)+1))\n",
    "\n",
    "all_node_subsets = [frozenset(subset) for subset in powerset(range(4))]\n",
    "nodeSubset2pairs = dict()\n",
    "for node_subset in all_node_subsets:\n",
    "    nodeSubset2pairs[node_subset] = frozenset([frozenset(pair_) for pair_ in combinations(node_subset, 2)])\n",
    "\n",
    "all_pairs_subsets = [frozenset(subset) for subset in powerset(all_pairs)]  # in total 2^6 = 64 subsets\n",
    "\n",
    "# if the pairs in {key} have been covered, sampling the nodes in {value} together is useless\n",
    "# i.e., the pairs between the nodes in {value} have been covered\n",
    "coveredParis2uselessSubset = defaultdict(list)\n",
    "for pair_subset in all_pairs_subsets:\n",
    "    for node_subset, pairs_set in nodeSubset2pairs.items():\n",
    "        if pairs_set.issubset(pair_subset):  # all the pairs between the nodes in node_subset have been covered\n",
    "            coveredParis2uselessSubset[pair_subset].append(node_subset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "motif2pairs = defaultdict(list)\n",
    "\n",
    "# - There are eleven possible 4-motifs in total (allowing isolated nodes):\n",
    "#     - {0}(0-1) An empty graph\n",
    "#     - {1}(1-1) A single edge\n",
    "#     - {2}(2-1) Two disconnected edges\n",
    "#     - {3}(2-2) Two connected edges (i.e., wedge or open triangle)\n",
    "#     - {4}(3-1) A 3-path\n",
    "#     - {5}(3-2) A triangle\n",
    "#     - {6}(3-3) A 3-star\n",
    "#     - {7}(4-1) A 4-cycle\n",
    "#     - {8}(4-2) A triangle + an edge\n",
    "#     - {9}(5-1) Two triangles sharing a common edge\n",
    "#     - {10}(6-1) A 4-clique\n",
    "\n",
    "# 0. An empty graph\n",
    "motif2pairs[0] = [frozenset()]\n",
    "\n",
    "# 1. A single edge\n",
    "for pair in all_pairs:\n",
    "    motif2pairs[1].append(frozenset([pair]))\n",
    "\n",
    "# 2. Two disconnected edges\n",
    "# 3. Two connected edges (i.e., wedge or open triangle)\n",
    "\n",
    "for pair1, pair2 in combinations(all_pairs, 2):\n",
    "    if len(pair1 & pair2) == 0:\n",
    "        motif2pairs[2].append(frozenset([pair1, pair2]))\n",
    "    else:\n",
    "        motif2pairs[3].append(frozenset([pair1, pair2]))\n",
    "\n",
    "# 4. A 3-path\n",
    "# first choose the two end points\n",
    "for v_start, v_end in combinations(range(4), 2):\n",
    "    remaining_nodes = set(range(4)) - {v_start, v_end}\n",
    "    for v_mid in remaining_nodes:\n",
    "        v_other = remaining_nodes - {v_mid}\n",
    "        v_other = v_other.pop()\n",
    "        # path: v_start -> v_mid -> v_other -> v_end\n",
    "        motif2pairs[4].append(frozenset([frozenset([v_start, v_mid]), frozenset([v_mid, v_other]), frozenset([v_other, v_end])]))\n",
    "\n",
    "# 5. A triangle\n",
    "for v1, v2, v3 in combinations(range(4), 3):\n",
    "    motif2pairs[5].append(frozenset([frozenset([v1, v2]), frozenset([v2, v3]), frozenset([v3, v1])]))\n",
    "\n",
    "# 6. A 3-star\n",
    "for center in range(4):\n",
    "    v1, v2, v3 = set(range(4)) - {center}\n",
    "    motif2pairs[6].append(frozenset([frozenset([center, v1]), frozenset([center, v2]), frozenset([center, v3])]))\n",
    "\n",
    "# 7. A 4-cycle\n",
    "# choose the node opposite to node 0\n",
    "for v_oppo in range(1, 4):\n",
    "    # cycle: 0 -> v1 -> v_oppo -> v2 -> 0\n",
    "    remaining_nodes = set(range(4)) - {0, v_oppo}\n",
    "    v1, v2 = remaining_nodes\n",
    "    motif2pairs[7].append(frozenset([frozenset([0, v1]), frozenset([v1, v_oppo]), frozenset([v_oppo, v2]), frozenset([v2, 0])]))\n",
    "\n",
    "# 8. A triangle + an edge\n",
    "for v1, v2, v3 in combinations(range(4), 3):\n",
    "    remaining_nodes = set(range(4)) - {v1, v2, v3}\n",
    "    v4 = remaining_nodes.pop()\n",
    "    motif2pairs[8].append(frozenset([frozenset([v1, v2]), frozenset([v2, v3]), frozenset([v3, v1]), frozenset([v1, v4])]))\n",
    "    motif2pairs[8].append(frozenset([frozenset([v1, v2]), frozenset([v2, v3]), frozenset([v3, v1]), frozenset([v2, v4])]))\n",
    "    motif2pairs[8].append(frozenset([frozenset([v1, v2]), frozenset([v2, v3]), frozenset([v3, v1]), frozenset([v3, v4])]))\n",
    "\n",
    "# 9. Two triangles sharing a common edge\n",
    "# choose the common edge\n",
    "for v1, v2 in combinations(range(4), 2):\n",
    "    remaining_nodes = set(range(4)) - {v1, v2}\n",
    "    v3, v4 = remaining_nodes\n",
    "    # edges: v1-v2, v1-v3, v1-v4, v2-v3, v2-v4\n",
    "    motif2pairs[9].append(frozenset([frozenset([v1, v2]), frozenset([v1, v3]), frozenset([v1, v4]), frozenset([v2, v3]), frozenset([v2, v4])]))\n",
    "\n",
    "# 10. A 4-clique\n",
    "motif2pairs[10] = [frozenset(all_pairs)]\n",
    "\n",
    "# pairs2motif: for each combination of pairs, find the corresponding motif\n",
    "pairs2motif = dict()\n",
    "for motif, pairs_list in motif2pairs.items():\n",
    "    for pairs in pairs_list:\n",
    "        pairs2motif[pairs] = motif\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "EPS = 1e-6\n",
    "\n",
    "def compute_pg_dict(g_nodes):\n",
    "    # the probability that a specific subset of nodes is sampled together in each round\n",
    "    pg_dict = {}\n",
    "    pg_dict[frozenset()] = (1 - g_nodes).prod()\n",
    "    pg_dict[frozenset([0])] = g_nodes[0] * ((1 - g_nodes[[1, 2, 3]]).prod())\n",
    "    pg_dict[frozenset([1])] = g_nodes[1] * ((1 - g_nodes[[0, 2, 3]]).prod())\n",
    "    pg_dict[frozenset([2])] = g_nodes[2] * ((1 - g_nodes[[0, 1, 3]]).prod())\n",
    "    pg_dict[frozenset([3])] = g_nodes[3] * ((1 - g_nodes[[0, 1, 2]]).prod())\n",
    "    pg_dict[frozenset([0, 1])] = g_nodes[0] * g_nodes[1] * (1 - g_nodes[[2, 3]]).prod()\n",
    "    pg_dict[frozenset([0, 2])] = g_nodes[0] * g_nodes[2] * (1 - g_nodes[[1, 3]]).prod()\n",
    "    pg_dict[frozenset([0, 3])] = g_nodes[0] * g_nodes[3] * (1 - g_nodes[[1, 2]]).prod()\n",
    "    pg_dict[frozenset([1, 2])] = g_nodes[1] * g_nodes[2] * (1 - g_nodes[[0, 3]]).prod()\n",
    "    pg_dict[frozenset([1, 3])] = g_nodes[1] * g_nodes[3] * (1 - g_nodes[[0, 2]]).prod()\n",
    "    pg_dict[frozenset([2, 3])] = g_nodes[2] * g_nodes[3] * (1 - g_nodes[[0, 1]]).prod()\n",
    "    pg_dict[frozenset([0, 1, 2])] = g_nodes[[0, 1, 2]].prod() * (1 - g_nodes[3])\n",
    "    pg_dict[frozenset([0, 1, 3])] = g_nodes[[0, 1, 3]].prod() * (1 - g_nodes[2])\n",
    "    pg_dict[frozenset([0, 2, 3])] = g_nodes[[0, 2, 3]].prod() * (1 - g_nodes[1])\n",
    "    pg_dict[frozenset([1, 2, 3])] = g_nodes[[1, 2, 3]].prod() * (1 - g_nodes[0])\n",
    "    pg_dict[frozenset([0, 1, 2, 3])] = g_nodes.prod()\n",
    "    \n",
    "    return pg_dict\n",
    "\n",
    "def sample_motif_probs(seq, cov, cov_acc, p_nodes, pg_dict, R):\n",
    "    # seq: a sampling sequence\n",
    "    # cov: an accumulated coverage history\n",
    "    # p_nodes: a 2d tensor of shape (4, 4)    \n",
    "    # pg_dict: pg_dict[node_subset] = Pr[node_subset are sampled together in each round]\n",
    "    # R: an integer scalar\n",
    "    \n",
    "    # in R rounds, {seq} is a subsequence of the whole length-R sampling sequence\n",
    "    len_seq = len(seq)\n",
    "    n_remain_slots = R - len_seq\n",
    "    \n",
    "    # there are (len_seq + 1) possible positions to insert the remaining sampling rounds\n",
    "    # and those remaining rounds should be \"useless\" according to the accumulated coverage history\n",
    "    \n",
    "    # now, based on the accumulated coverage history {cov}, compute the probability of useless subsets\n",
    "    assert len(cov_acc) == len_seq + 1\n",
    "    sequence_prob = 1.0\n",
    "    for node_subset in seq:\n",
    "        node_subset = frozenset(node_subset)\n",
    "        sequence_prob *= pg_dict[node_subset]\n",
    "    useless_probs = torch.zeros(len_seq + 1, device=device)\n",
    "    for i in range(len_seq + 1):\n",
    "        covered_pairs_before_i = cov_acc[i]\n",
    "        covered_pairs_before_i = frozenset([frozenset(pair) for pair in covered_pairs_before_i])\n",
    "        useless_subsets_before_i = coveredParis2uselessSubset[covered_pairs_before_i]\n",
    "        useless_probs[i] = sum(pg_dict[node_subset] for node_subset in useless_subsets_before_i)            \n",
    "    \n",
    "    # the probability of the sequence is sequence_prob * {STAR}\n",
    "    # {STAR} = \\sum_{n1 + n2 + ... + n_{len_seq + 1} = n_remain_slots} \\prod_{i=1}^{len_seq + 1} useless_probs[i]^{n_i}        \n",
    "    # Using generating function -->\n",
    "    # {STAR} = \\sum_{i} useless_probs[i]^{n_remain_slots} / (\\prod_{j \\neq i} (1 - useless_probs[j] / useless_probs[i]))\n",
    "    star = 0.0\n",
    "    for i in range(len_seq + 1):\n",
    "        num_i = useless_probs[i] ** n_remain_slots\n",
    "        den_i = 1.0\n",
    "        for j in range(len_seq + 1):\n",
    "            if j != i:\n",
    "                den_i *= (1 - useless_probs[j] / (useless_probs[i] + EPS))\n",
    "        star += num_i / den_i\n",
    "    \n",
    "    prob_seq = sequence_prob * star\n",
    "    \n",
    "    # compute the motif probabilities\n",
    "    motif_probs = torch.zeros(11, device=device)\n",
    "    \n",
    "    # for each subset of pairs in the coverage {cov}, compute the probability of results\n",
    "    pair2prob = {}\n",
    "    pair2prob[frozenset([0, 1])] = p_nodes[0, 1]\n",
    "    pair2prob[frozenset([0, 2])] = p_nodes[0, 2]\n",
    "    pair2prob[frozenset([0, 3])] = p_nodes[0, 3]\n",
    "    pair2prob[frozenset([1, 2])] = p_nodes[1, 2]\n",
    "    pair2prob[frozenset([1, 3])] = p_nodes[1, 3]\n",
    "    pair2prob[frozenset([2, 3])] = p_nodes[2, 3]\n",
    "    \n",
    "    pairs2prob_list = [dict() for _ in cov]\n",
    "    \n",
    "    for i_, cov_ in enumerate(cov):        \n",
    "        pairs_in_cov = [frozenset(pair) for pair in cov_]\n",
    "        probs_in_cov = [pair2prob[pair] for pair in pairs_in_cov]\n",
    "        \n",
    "        # sort the pairs w.r.t their probabilities, also get the corresponding probabilities (small to large)\n",
    "        sorted_probs_in_cov, sorted_pairs_in_cov = zip(*sorted(zip(probs_in_cov, pairs_in_cov), reverse=False))\n",
    "        \n",
    "        for j_ in range(len(sorted_probs_in_cov)):\n",
    "            pairs_from_j = sorted_pairs_in_cov[j_:]\n",
    "            prob_from_j = sorted_probs_in_cov[j_] if j_ == 0 else sorted_probs_in_cov[j_] - sorted_probs_in_cov[j_ - 1]\n",
    "            pairs2prob_list[i_][frozenset(pairs_from_j)] = prob_from_j\n",
    "        pairs2prob_list[i_][frozenset()] = 1.0 - sorted_probs_in_cov[-1]\n",
    "        \n",
    "    # now consider the combinations\n",
    "    for pairs_comb in product(*pairs2prob_list):\n",
    "        pairs_comb = [frozenset(pairs) for pairs in pairs_comb]\n",
    "        probs_comb = [pairs2prob_list[i_][pairs] for i_, pairs in enumerate(pairs_comb)]\n",
    "        prob_comb = torch.prod(torch.tensor(probs_comb, device=device))\n",
    "        total_pairs_comb = frozenset().union(*pairs_comb)                \n",
    "        i_motif = pairs2motif[total_pairs_comb]\n",
    "        motif_probs[i_motif] += prob_comb        \n",
    "    \n",
    "    return prob_seq, motif_probs\n",
    "\n",
    "def motif_probs_indep(p_nodes):\n",
    "    # given the probabilities of each pair, compute the motif probabilities when all the pairs are independent\n",
    "    motif_probs = torch.zeros(11, device=device)\n",
    "    \n",
    "    pair2prob = {}\n",
    "    pair2prob[frozenset([0, 1])] = p_nodes[0, 1]\n",
    "    pair2prob[frozenset([0, 2])] = p_nodes[0, 2]\n",
    "    pair2prob[frozenset([0, 3])] = p_nodes[0, 3]\n",
    "    pair2prob[frozenset([1, 2])] = p_nodes[1, 2]\n",
    "    pair2prob[frozenset([1, 3])] = p_nodes[1, 3]\n",
    "    pair2prob[frozenset([2, 3])] = p_nodes[2, 3]       \n",
    "    \n",
    "    for pair_subset in all_pairs_subsets:\n",
    "        pairs_not_exist = frozenset(all_pairs) - pair_subset\n",
    "        prob_ = 1.0\n",
    "        for pair in pair_subset:\n",
    "            prob_ *= pair2prob[pair]\n",
    "        for pair in pairs_not_exist:\n",
    "            prob_ *= (1 - pair2prob[pair])\n",
    "        i_motif = pairs2motif[pair_subset]\n",
    "        motif_probs[i_motif] += prob_\n",
    "\n",
    "    return motif_probs\n",
    "\n",
    "\n",
    "def total_motif_probs(seq_list, cov_list, cov_acc_list, p, g, R):\n",
    "    # seq_list: a list of node sampling sequences\n",
    "    # cov_list: a list of coverage histories\n",
    "    # cov_acc_list: a list of accumulated coverage histories\n",
    "    # p: a 2d tensor of shape (n, n)\n",
    "    # g: a 1d tensor of shape (n)\n",
    "    # R: an integer scalar\n",
    "\n",
    "    n_nodes = p.size(0)\n",
    "    assert p.size(1) == n_nodes\n",
    "    assert g.size(0) == n_nodes\n",
    "\n",
    "    nodes = torch.arange(n_nodes, device=device)\n",
    "\n",
    "    # there are 11 possible motifs\n",
    "    motif_num = torch.zeros(11, device=device)\n",
    "\n",
    "    # for each subset of nodes of size 4\n",
    "    for nodes in tqdm(torch.combinations(nodes, 4), desc=\"Total motifs\"):\n",
    "        remaining_sample_probs = 1.0\n",
    "        p_nodes = p[nodes][:, nodes]\n",
    "        g_nodes = g[nodes]\n",
    "        # for each possible way of covering the nodes\n",
    "        for seq, cov, cov_acc in tqdm(zip(seq_list, cov_list, cov_acc_list), desc=\"Covering ways\", total=len(seq_list)):\n",
    "            pg_dict = compute_pg_dict(g_nodes)\n",
    "            # compute the probability of this specific way of covering and the corresponding motif probabilities\n",
    "            sample_probs_i, motif_probs_i = sample_motif_probs(\n",
    "                seq, cov, cov_acc, p_nodes, pg_dict, R\n",
    "            )\n",
    "            motif_num += motif_probs_i * sample_probs_i\n",
    "            remaining_sample_probs -= sample_probs_i        \n",
    "        motif_num += motif_probs_indep(p_nodes) * remaining_sample_probs\n",
    "    \n",
    "    return motif_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "\n",
    "# a random edge probability matrix\n",
    "p = torch.rand(n, n, device=device)\n",
    "p = (p + p.t()) / 2\n",
    "# clean the diagonal\n",
    "p.fill_diagonal_(0.0)\n",
    "\n",
    "# a random node sampling probability\n",
    "g = torch.rand(n, device=device)\n",
    "\n",
    "R = 100_000\n",
    "\n",
    "total_motif_probs(sequence_list, coverage_list, accumulated_coverage_list, p, g, R)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
