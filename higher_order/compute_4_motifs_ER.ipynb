{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich import traceback\n",
    "\n",
    "traceback.install()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"possible_cases_4.txt\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "# examples\n",
    "# Sequence: [(0, 1), (0, 2), (0, 3), (1, 2), (1, 2, 3)]\n",
    "# Coverage history: [{(0, 1)}, {(0, 2)}, {(0, 3)}, {(1, 2)}, {(2, 3), (1, 3)}]\n",
    "\n",
    "# Sequence: [(0, 1), (0, 2), (0, 3), (1, 2), (0, 1, 2, 3)]\n",
    "# Coverage history: [{(0, 1)}, {(0, 2)}, {(0, 3)}, {(1, 2)}, {(2, 3), (1, 3)}]\n",
    "\n",
    "# Sequence: [(0, 1), (0, 2), (0, 3), (1, 3), (1, 2, 3)]\n",
    "# Coverage history: [{(0, 1)}, {(0, 2)}, {(0, 3)}, {(1, 3)}, {(2, 3), (1, 2)}]\n",
    "\n",
    "sequence_list = []\n",
    "coverage_list = []\n",
    "for line in lines:\n",
    "    line = line.strip()\n",
    "    if line.startswith(\"Sequence\"):\n",
    "        sequence = eval(line.split(\":\")[1])\n",
    "        sequence_list.append(sequence)\n",
    "    if line.startswith(\"Coverage history\"):\n",
    "        coverage = eval(line.split(\":\")[1])\n",
    "        coverage_list.append(coverage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(sequence_list))\n",
    "print(len(coverage_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- There are eleven possible 4-motifs in total (allowing isolated nodes):\n",
    "    - {0}(0-1) An empty graph\n",
    "    - {1}(1-1) A single edge\n",
    "    - {2}(2-1) Two disconnected edges\n",
    "    - {3}(2-2) Two connected edges (i.e., wedge or open triangle)\n",
    "    - {4}(3-1) A 3-path\n",
    "    - {5}(3-2) A triangle\n",
    "    - {6}(3-3) A 3-star\n",
    "    - {7}(4-1) A 4-cycle\n",
    "    - {8}(4-2) A triangle + an edge\n",
    "    - {9}(5-1) Two triangles sharing a common edge\n",
    "    - {10}(6-1) A 4-clique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert each \"coverage\" to an accumulated coverage\n",
    "accumulated_coverage_list = []\n",
    "for coverage in coverage_list:\n",
    "    accumulated_coverage = [frozenset()]\n",
    "    for cov in coverage:\n",
    "        accumulated_coverage.append(accumulated_coverage[-1] | cov)\n",
    "    accumulated_coverage_list.append(accumulated_coverage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from itertools import combinations, chain\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda:1\")\n",
    "\n",
    "all_pairs = list(combinations(range(4), 2))  # in total 6 pairs\n",
    "all_pairs = [frozenset(pair) for pair in all_pairs]\n",
    "\n",
    "# https://stackoverflow.com/questions/1482308\n",
    "def powerset(iterable):\n",
    "    \"powerset([1,2,3]) --> () (1,) (2,) (3,) (1,2) (1,3) (2,3) (1,2,3)\"\n",
    "    s = list(iterable)\n",
    "    return chain.from_iterable(combinations(s, r) for r in range(len(s)+1))\n",
    "\n",
    "all_node_subsets = [frozenset(subset) for subset in powerset(range(4))]\n",
    "nodeSubset2pairs = dict()\n",
    "for node_subset in all_node_subsets:\n",
    "    nodeSubset2pairs[node_subset] = frozenset([frozenset(pair_) for pair_ in combinations(node_subset, 2)])\n",
    "\n",
    "all_pairs_subsets = [frozenset(subset) for subset in powerset(all_pairs)]  # in total 2^6 = 64 subsets\n",
    "\n",
    "# if the pairs in {key} have been covered, sampling the nodes in {value} together is useless\n",
    "# i.e., the pairs between the nodes in {value} have been covered\n",
    "coveredParis2uselessSubset = defaultdict(list)\n",
    "for pair_subset in all_pairs_subsets:\n",
    "    for node_subset, pairs_set in nodeSubset2pairs.items():\n",
    "        if pairs_set.issubset(pair_subset):  # all the pairs between the nodes in node_subset have been covered\n",
    "            coveredParis2uselessSubset[pair_subset].append(node_subset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "motif2pairs = defaultdict(list)\n",
    "\n",
    "# - There are eleven possible 4-motifs in total (allowing isolated nodes):\n",
    "#     - {0}(0-1) An empty graph\n",
    "#     - {1}(1-1) A single edge\n",
    "#     - {2}(2-1) Two disconnected edges\n",
    "#     - {3}(2-2) Two connected edges (i.e., wedge or open triangle)\n",
    "#     - {4}(3-1) A 3-path\n",
    "#     - {5}(3-2) A triangle\n",
    "#     - {6}(3-3) A 3-star\n",
    "#     - {7}(4-1) A 4-cycle\n",
    "#     - {8}(4-2) A triangle + an edge\n",
    "#     - {9}(5-1) Two triangles sharing a common edge\n",
    "#     - {10}(6-1) A 4-clique\n",
    "\n",
    "# 0. An empty graph\n",
    "motif2pairs[0] = [frozenset()]\n",
    "\n",
    "# 1. A single edge\n",
    "for pair in all_pairs:\n",
    "    motif2pairs[1].append(frozenset([pair]))\n",
    "\n",
    "# 2. Two disconnected edges\n",
    "# 3. Two connected edges (i.e., wedge or open triangle)\n",
    "\n",
    "for pair1, pair2 in combinations(all_pairs, 2):\n",
    "    if len(pair1 & pair2) == 0:\n",
    "        motif2pairs[2].append(frozenset([pair1, pair2]))\n",
    "    else:\n",
    "        motif2pairs[3].append(frozenset([pair1, pair2]))\n",
    "\n",
    "# 4. A 3-path\n",
    "# first choose the two end points\n",
    "for v_start, v_end in combinations(range(4), 2):\n",
    "    remaining_nodes = set(range(4)) - {v_start, v_end}\n",
    "    for v_mid in remaining_nodes:\n",
    "        v_other = remaining_nodes - {v_mid}\n",
    "        v_other = v_other.pop()\n",
    "        # path: v_start -> v_mid -> v_other -> v_end\n",
    "        motif2pairs[4].append(frozenset([frozenset([v_start, v_mid]), frozenset([v_mid, v_other]), frozenset([v_other, v_end])]))\n",
    "\n",
    "# 5. A triangle\n",
    "for v1, v2, v3 in combinations(range(4), 3):\n",
    "    motif2pairs[5].append(frozenset([frozenset([v1, v2]), frozenset([v2, v3]), frozenset([v3, v1])]))\n",
    "\n",
    "# 6. A 3-star\n",
    "for center in range(4):\n",
    "    v1, v2, v3 = set(range(4)) - {center}\n",
    "    motif2pairs[6].append(frozenset([frozenset([center, v1]), frozenset([center, v2]), frozenset([center, v3])]))\n",
    "\n",
    "# 7. A 4-cycle\n",
    "# choose the node opposite to node 0\n",
    "for v_oppo in range(1, 4):\n",
    "    # cycle: 0 -> v1 -> v_oppo -> v2 -> 0\n",
    "    remaining_nodes = set(range(4)) - {0, v_oppo}\n",
    "    v1, v2 = remaining_nodes\n",
    "    motif2pairs[7].append(frozenset([frozenset([0, v1]), frozenset([v1, v_oppo]), frozenset([v_oppo, v2]), frozenset([v2, 0])]))\n",
    "\n",
    "# 8. A triangle + an edge\n",
    "for v1, v2, v3 in combinations(range(4), 3):\n",
    "    remaining_nodes = set(range(4)) - {v1, v2, v3}\n",
    "    v4 = remaining_nodes.pop()\n",
    "    motif2pairs[8].append(frozenset([frozenset([v1, v2]), frozenset([v2, v3]), frozenset([v3, v1]), frozenset([v1, v4])]))\n",
    "    motif2pairs[8].append(frozenset([frozenset([v1, v2]), frozenset([v2, v3]), frozenset([v3, v1]), frozenset([v2, v4])]))\n",
    "    motif2pairs[8].append(frozenset([frozenset([v1, v2]), frozenset([v2, v3]), frozenset([v3, v1]), frozenset([v3, v4])]))\n",
    "\n",
    "# 9. Two triangles sharing a common edge\n",
    "# choose the common edge\n",
    "for v1, v2 in combinations(range(4), 2):\n",
    "    remaining_nodes = set(range(4)) - {v1, v2}\n",
    "    v3, v4 = remaining_nodes\n",
    "    # edges: v1-v2, v1-v3, v1-v4, v2-v3, v2-v4\n",
    "    motif2pairs[9].append(frozenset([frozenset([v1, v2]), frozenset([v1, v3]), frozenset([v1, v4]), frozenset([v2, v3]), frozenset([v2, v4])]))\n",
    "\n",
    "# 10. A 4-clique\n",
    "motif2pairs[10] = [frozenset(all_pairs)]\n",
    "\n",
    "# pairs2motif: for each combination of pairs, find the corresponding motif\n",
    "pairs2motif = dict()\n",
    "for motif, pairs_list in motif2pairs.items():\n",
    "    for pairs in pairs_list:\n",
    "        pairs2motif[pairs] = motif\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erdos-Renyi model\n",
    "from itertools import product\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "EPS = 1e-6\n",
    "\n",
    "def compute_pg_dict(g):\n",
    "    # the probability that a specific subset of nodes is sampled together in each round\n",
    "    pg_dict = {}\n",
    "    pg_dict[frozenset()] = (1 - g) ** 4\n",
    "    pg_dict[frozenset([0])] = g * ((1 - g) ** 3)\n",
    "    pg_dict[frozenset([1])] = g * ((1 - g) ** 3)\n",
    "    pg_dict[frozenset([2])] = g * ((1 - g) ** 3)\n",
    "    pg_dict[frozenset([3])] = g * ((1 - g) ** 3)\n",
    "    pg_dict[frozenset([0, 1])] = g ** 2 * ((1 - g) ** 2)\n",
    "    pg_dict[frozenset([0, 2])] = g ** 2 * ((1 - g) ** 2)\n",
    "    pg_dict[frozenset([0, 3])] = g ** 2 * ((1 - g) ** 2)\n",
    "    pg_dict[frozenset([1, 2])] = g ** 2 * ((1 - g) ** 2)\n",
    "    pg_dict[frozenset([1, 3])] = g ** 2 * ((1 - g) ** 2)\n",
    "    pg_dict[frozenset([2, 3])] = g ** 2 * ((1 - g) ** 2)\n",
    "    pg_dict[frozenset([0, 1, 2])] = g ** 3 * (1 - g)\n",
    "    pg_dict[frozenset([0, 1, 3])] = g ** 3 * (1 - g)\n",
    "    pg_dict[frozenset([0, 2, 3])] = g ** 3 * (1 - g)\n",
    "    pg_dict[frozenset([1, 2, 3])] = g ** 3 * (1 - g)\n",
    "    pg_dict[frozenset([0, 1, 2, 3])] = g ** 4\n",
    "    \n",
    "    return pg_dict\n",
    "\n",
    "def clique_prob(seq, cov, cov_acc, p, pg_dict, R):\n",
    "    # seq: a sampling sequence\n",
    "    # cov: an accumulated coverage history\n",
    "    # p: a scalar in [0, 1]    \n",
    "    # pg_dict: pg_dict[node_subset] = Pr[node_subset are sampled together in each round]\n",
    "    # R: an integer scalar\n",
    "    \n",
    "    # in R rounds, {seq} is a subsequence of the whole length-R sampling sequence\n",
    "    len_seq = len(seq)\n",
    "    n_remain_slots = R - len_seq\n",
    "    \n",
    "    # there are (len_seq + 1) possible positions to insert the remaining sampling rounds\n",
    "    # and those remaining rounds should be \"useless\" according to the accumulated coverage history\n",
    "    \n",
    "    # now, based on the accumulated coverage history {cov}, compute the probability of useless subsets\n",
    "    assert len(cov_acc) == len_seq + 1\n",
    "    sequence_prob = 1.0\n",
    "    for node_subset in seq:\n",
    "        node_subset = frozenset(node_subset)\n",
    "        sequence_prob *= pg_dict[node_subset]\n",
    "    useless_probs = torch.zeros(len_seq + 1, device=device)\n",
    "    for i in range(len_seq + 1):\n",
    "        covered_pairs_before_i = cov_acc[i]\n",
    "        covered_pairs_before_i = frozenset([frozenset(pair) for pair in covered_pairs_before_i])\n",
    "        useless_subsets_before_i = coveredParis2uselessSubset[covered_pairs_before_i]        \n",
    "        useless_probs[i] = sum(pg_dict[node_subset] for node_subset in useless_subsets_before_i)    \n",
    "    \n",
    "    # the probability of the sequence is sequence_prob * {STAR}\n",
    "    # {STAR} = \\sum_{n1 + n2 + ... + n_{len_seq + 1} = n_remain_slots} \\prod_{i=1}^{len_seq + 1} useless_probs[i]^{n_i}        \n",
    "    # Using generating function -->\n",
    "    # {STAR} = \\sum_{i} useless_probs[i]^{n_remain_slots} / (\\prod_{j \\neq i} (1 - useless_probs[j] / useless_probs[i]))\n",
    "    star = 0.0\n",
    "    for i in range(len_seq + 1):\n",
    "        num_i = useless_probs[i] ** n_remain_slots\n",
    "        den_i = 1.0\n",
    "        for j in range(len_seq + 1):\n",
    "            if j != i:\n",
    "                den_i *= (1 - useless_probs[j] / (useless_probs[i] + EPS))\n",
    "        star += num_i / den_i\n",
    "    \n",
    "    prob_seq = sequence_prob * star\n",
    "    prob_clique = p ** len(cov)\n",
    "    \n",
    "    return prob_seq, prob_clique\n",
    "\n",
    "def motif_probs_indep(p):\n",
    "    # given the probabilities of each pair, compute the clique probability when all the pairs are independent\n",
    "    return p ** 6  # 6 pairs in total\n",
    "\n",
    "\n",
    "def total_clique_prob(seq_list, cov_list, cov_acc_list, p, g, R):\n",
    "    # seq_list: a list of node sampling sequences\n",
    "    # cov_list: a list of coverage histories\n",
    "    # cov_acc_list: a list of accumulated coverage histories\n",
    "    # p: a scalar in [0, 1]\n",
    "    # g: a scalar in [0, 1]\n",
    "    # R: an integer scalar\n",
    "    \n",
    "    remaining_sample_probs = 1.0\n",
    "    \n",
    "    pg_dict = compute_pg_dict(g)\n",
    "    \n",
    "    clique_prob_total = 0.0\n",
    "    \n",
    "    # for each possible way of covering the nodes\n",
    "    for seq, cov, cov_acc in tqdm(zip(seq_list, cov_list, cov_acc_list), desc=\"Covering ways\", total=len(seq_list)):        \n",
    "        # compute the probability of this specific way of covering and the corresponding clique probabilitie\n",
    "        sample_probs_i, clique_prob_i = clique_prob(seq, cov, cov_acc, p, pg_dict, R)\n",
    "        clique_prob_total += clique_prob_i * sample_probs_i\n",
    "        remaining_sample_probs -= sample_probs_i\n",
    "    clique_prob_total += motif_probs_indep(p) * remaining_sample_probs\n",
    "    \n",
    "    return clique_prob_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "\n",
    "# facebook\n",
    "p = 0.010819963503439\n",
    "clique_prob_gt = 2.709879581603210E-06\n",
    "\n",
    "# hamsterster\n",
    "p = 0.008052526263132\n",
    "clique_prob_gt = 1.984523113390000E-07\n",
    "\n",
    "# bio-CE-PG\n",
    "p = 0.033069665158194\n",
    "clique_prob_gt = 2.823725172688640E-05\n",
    "\n",
    "# bio-SC-HT\n",
    "p = 0.029232450464441\n",
    "clique_prob_gt = 3.401867212812720E-05\n",
    "\n",
    "# polblogs\n",
    "p = 0.022407916024937\n",
    "clique_prob_gt = 4.567827375694790E-06\n",
    "\n",
    "# web-spam\n",
    "p = 0.003290122036898\n",
    "clique_prob_gt = 1.742051669352390E-08\n",
    "\n",
    "g = 0.02\n",
    "\n",
    "p = torch.tensor(p, device=device, dtype=torch.float64)\n",
    "\n",
    "g = torch.tensor(g, device=device, dtype=torch.float64)\n",
    "\n",
    "g = torch.nn.Parameter(g)\n",
    "\n",
    "# using gradient descent to optimize g\n",
    "\n",
    "optimizer = Adam([g], lr=1)\n",
    "\n",
    "R = 100_000\n",
    "\n",
    "for epoch in range(1000):\n",
    "    optimizer.zero_grad()\n",
    "    total_clique_prob_val = total_clique_prob(sequence_list, coverage_list, accumulated_coverage_list, p, g, R)\n",
    "    loss = (total_clique_prob_val - clique_prob_gt) ** 2\n",
    "    print(f\"Epoch {epoch}, g = {g.item()}, {total_clique_prob_val.item()}, {clique_prob_gt}, loss = {loss.item()}\")\n",
    "    loss.backward()\n",
    "    print(g.grad)\n",
    "    optimizer.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
