{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ER iid\n",
    "# $n$: Fixed as 1,024\n",
    "# $p$: Fixed as 0.01\n",
    "# $g$: 0 to 0.1, step size 0.01\n",
    "# $R$: Fixed as 100,000 (as in our main experiments)\n",
    "\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from decimal import Decimal, getcontext\n",
    "\n",
    "getcontext().prec = 50\n",
    "\n",
    "n = 1024\n",
    "p = 0.01\n",
    "p_string = str(p).replace(\".\", \"p\")\n",
    "R = 100000\n",
    "g_list = np.arange(0, 0.11, 0.01)\n",
    "g_string_list = [\"0p0\", \"0p01\", \"0p02\", \"0p03\", \"0p04\", \"0p05\", \"0p06\", \"0p07\", \"0p08\", \"0p09\", \"0p1\"]\n",
    "\n",
    "n_dec = Decimal(\"1024\")\n",
    "p_dec = Decimal(\"0.01\")\n",
    "R_dec = Decimal(\"100000\")\n",
    "\n",
    "p_save = Path(\"ER_iid\")\n",
    "p_save.mkdir(exist_ok=True)\n",
    "\n",
    "for g, g_string in zip(g_list, g_string_list):\n",
    "    g_dec = Decimal(str(g))\n",
    "    try:\n",
    "        p_round = (1 - (1 - p_dec) ** (1 / R_dec)) / (g_dec * g_dec)\n",
    "    except:\n",
    "        p_round = 0\n",
    "            \n",
    "    with open(p_save / f\"n{n}_p{p_string}_g{g_string}_R{R}.txt\", \"w+\") as f:\n",
    "        # read the input file: number of nodes, density, binding strength, number of rounds\n",
    "        f.write(f\"{n} {p} {g} {R} {p_round}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ER iter\n",
    "# $n$: Fixed as 1,024\n",
    "# $p$: Fixed as 0.01\n",
    "# $g$: 0 to 0.1, step size 0.01\n",
    "# $R$: Fixed as 100,000 (as in our main experiments)\n",
    "\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from decimal import Decimal, getcontext\n",
    "\n",
    "getcontext().prec = 50\n",
    "\n",
    "n = 1024\n",
    "p = 0.01\n",
    "p_string = str(p).replace(\".\", \"p\")\n",
    "R = 100000\n",
    "g_list = np.arange(0, 0.11, 0.01)\n",
    "g_string_list = [\"0p0\", \"0p01\", \"0p02\", \"0p03\", \"0p04\", \"0p05\", \"0p06\", \"0p07\", \"0p08\", \"0p09\", \"0p1\"]\n",
    "\n",
    "n_dec = Decimal(\"1024\")\n",
    "p_dec = Decimal(\"0.01\")\n",
    "R_dec = Decimal(\"100000\")\n",
    "\n",
    "p_save = Path(\"ER_iter\")\n",
    "p_save.mkdir(exist_ok=True)\n",
    "\n",
    "for g, g_string in zip(g_list, g_string_list):\n",
    "    with open(p_save / f\"n{n}_p{p_string}_g{g_string}_R{R}.txt\", \"w+\") as f:\n",
    "        # read the input file: number of nodes, density, binding strength, number of rounds\n",
    "        f.write(f\"{n} {p} {g} {R}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CL\n",
    "# $n$: Fixed as 1,024\n",
    "# $p$: generating a power-law degree sequence $d_v$\n",
    "# - overall density 0.01 and the power-law exponent is -2\n",
    "# $g$: using the formula $g(d) = \\gamma d^\\alpha$ with \n",
    "# mean $g$: 0 to 0.1, step size 0.01\n",
    "# \\alpha: -1 (larger degree smaller $g$), 0 (same for all the nodes), 1 (larger degree larger $g$)\n",
    "# $R$: Fixed as 100,000 as in our main experiments\n",
    "\n",
    "from collections import defaultdict\n",
    "from itertools import product\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from networkx.algorithms.graphical import is_graphical\n",
    "from networkx.utils.random_sequence import powerlaw_sequence\n",
    "import pickle as pkl\n",
    "\n",
    "n = 1_024\n",
    "p = 0.01\n",
    "R = 100_000\n",
    "g_list = np.arange(0, 0.11, 0.01)\n",
    "alpha_list = [-0.3, 0, 0.3]\n",
    "t = 2\n",
    "\n",
    "p_save = Path(\"CL\")\n",
    "p_save.mkdir(exist_ok=True)\n",
    "\n",
    "if False:\n",
    "    # find a valid degree sequence\n",
    "    while True:  # Continue generating sequences until one of them is graphical\n",
    "        seq = sorted([int(round(d)) for d in powerlaw_sequence(n, t)], reverse=True)  # Round to nearest integer to obtain DISCRETE degree sequence\n",
    "        if is_graphical(seq):\n",
    "            n_edges = sum(seq) / 2\n",
    "            p_gen = n_edges / (n * (n - 1) / 2)\n",
    "            print(p_gen)\n",
    "            if abs(p_gen - p) < 0.001:\n",
    "                break\n",
    "\n",
    "    with open(p_save / \"deg_seq.txt\", \"w+\") as f:\n",
    "        for deg in seq:\n",
    "            f.write(f\"{deg}\\n\")\n",
    "            \n",
    "    with open(p_save / \"deg_seq.pkl\", \"wb\") as f:\n",
    "        pkl.dump(seq, f)\n",
    "\n",
    "with open(p_save / \"deg_seq.pkl\", \"rb\") as f:\n",
    "    deg_seq = pkl.load(f)\n",
    "\n",
    "for g, alpha in product(g_list, alpha_list):\n",
    "    weight_seq = [d ** alpha for d in deg_seq]\n",
    "    target_g_sum = g * len(deg_seq)\n",
    "    weight_seq = [w / sum(weight_seq) * target_g_sum for w in weight_seq]\n",
    "    \n",
    "    assert max(weight_seq) <= 1, f\"{max(weight_seq)}\"\n",
    "    \n",
    "    g_string = str(g).replace(\".\", \"p\")\n",
    "    alpha_string = str(alpha).replace(\".\", \"p\")\n",
    "    \n",
    "    # read the input file\n",
    "    # first line: n_round\n",
    "    # each line after that: degree, number of nodes with this degree, alpha of this degree\n",
    "    \n",
    "    deg2num = defaultdict(int)\n",
    "    deg2alpha = dict()\n",
    "    \n",
    "    for deg, w in zip(deg_seq, weight_seq):\n",
    "        deg2num[deg] += 1\n",
    "        deg2alpha[deg] = w\n",
    "            \n",
    "    with open(p_save / f\"n{n}_p{p}_g{g_string}_alpha{alpha_string}_R{R}.txt\", \"w+\") as f:\n",
    "        f.write(f\"{R}\\n\")\n",
    "        for deg, num in deg2num.items():\n",
    "            f.write(f\"{deg} {num} {deg2alpha[deg]}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SBM\n",
    "# $n$: Fixed as 1,024\n",
    "# Number of communities: 10\n",
    "# Community sizes: Generating a power-law size sequence with exponent -2\n",
    "# $p$: The intra-community edge probability and inter-community edge probability --> overall density 0.01\n",
    "# $g$: using the formula $g(v) = \\gamma {s_v}^\\alpha$ with \n",
    "# $s_v$ is the size of the community that contains $v$\n",
    "# mean $g$: 0 to 0.1, step size 0.01\n",
    "# \\alpha: -1 (larger community size smaller $g$), 0 (same for all the nodes), 1 (larger community size larger $g$)\n",
    "# $R$: Fixed as 100,000 as in our main experiments\n",
    "\n",
    "from collections import defaultdict\n",
    "from itertools import product\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from networkx.algorithms.graphical import is_graphical\n",
    "from networkx.utils.random_sequence import powerlaw_sequence\n",
    "import pickle as pkl\n",
    "\n",
    "n = 1_024\n",
    "n_comm = 10\n",
    "p = 0.01\n",
    "R = 100_000\n",
    "g_list = np.arange(0, 0.11, 0.01)\n",
    "alpha_list = [-0.5, 0, 0.5]\n",
    "t = 1.5\n",
    "\n",
    "p_save = Path(\"SBM\")\n",
    "p_save.mkdir(exist_ok=True)\n",
    "\n",
    "if False:\n",
    "    while True:\n",
    "        # generate community size sequence\n",
    "        seq = sorted([int(round(d)) for d in powerlaw_sequence(n_comm, t)], reverse=True)\n",
    "        if min(seq) <= 2:\n",
    "            continue\n",
    "        if abs((sum(seq) / n) - 1) < 0.01:\n",
    "            # adjust the size of the largest community to fit the total number of nodes\n",
    "            max_idx = seq.index(max(seq))\n",
    "            seq[max_idx] -= sum(seq) - n\n",
    "            break\n",
    "\n",
    "    with open(p_save / \"comm_size_seq.pkl\", \"wb\") as f:\n",
    "        pkl.dump(seq, f)\n",
    "\n",
    "# [545, 337, 49, 39, 16, 13, 9, 9, 4, 3]\n",
    "\n",
    "with open(p_save / \"comm_size_seq.pkl\", \"rb\") as f:\n",
    "    comm_seq = pkl.load(f)\n",
    "\n",
    "n_pair_intra = sum([s * (s - 1) / 2 for s in comm_seq])\n",
    "n_pair_inter = n * (n - 1) / 2 - n_pair_intra\n",
    "target_edges = n * (n - 1) / 2 * p\n",
    "\n",
    "p_intra = 0.02\n",
    "edges_intra = n_pair_intra * p_intra\n",
    "\n",
    "edges_inter = target_edges - edges_intra\n",
    "p_inter = edges_inter / n_pair_inter\n",
    "\n",
    "# print(p_intra, p_inter)\n",
    "\n",
    "for g, alpha in product(g_list, alpha_list):\n",
    "    weight_seq = [s ** alpha for s in comm_seq]\n",
    "    sum_weight_raw = sum(w * s for w, s in zip(weight_seq, comm_seq))\n",
    "    target_g_sum = g * n\n",
    "    weight_seq = [w / sum_weight_raw * target_g_sum for w in weight_seq]\n",
    "    assert max(weight_seq) <= 1, f\"{max(weight_seq)}\"\n",
    "    \n",
    "    g_string = str(g).replace(\".\", \"p\")\n",
    "    alpha_string = str(alpha).replace(\".\", \"p\")\n",
    "    \n",
    "    with open(p_save / f\"n{n}_p{p}_g{g_string}_alpha{alpha_string}_R{R}.txt\", \"w+\") as f:\n",
    "        # first line: n_blocks, n_round    \n",
    "        f.write(f\"{n_comm} {R}\\n\")\n",
    "        # after that, the n_blocks lines are the binding strength of each block\n",
    "        for s, w in zip(comm_seq, weight_seq):\n",
    "            f.write(f\"{w}\\n\")\n",
    "        # after that, the n_blocks lines are the probabilities of each block\n",
    "        for i, s in enumerate(comm_seq):\n",
    "            for j, s2 in enumerate(comm_seq):\n",
    "                if i == j:\n",
    "                    f.write(f\"{p_intra}\")\n",
    "                else:\n",
    "                    f.write(f\"{p_inter}\")\n",
    "                if j != len(comm_seq) - 1:\n",
    "                    f.write(\" \")\n",
    "            f.write(\"\\n\")\n",
    "        # finally, the n_blocks lines are the number of nodes in each block\n",
    "        for s in comm_seq:\n",
    "            f.write(f\"{s}\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kronecker\n",
    "# $n$: Fixed as 1,024 (Seed matrix $2 \\times 2$, Kronecker power 10)\n",
    "# $p$: Seed matrix [0.95, 0.63; 0.63, 0.32]\n",
    "# $g$: using the formula $g(v) = \\gamma (i_v + 1)^\\alpha$ with \n",
    "# $i_v$ is the number of ones in the binary node labels of $v$\n",
    "# mean $g$: 0 to 0.1, step size 0.01\n",
    "# \\alpha: -1 (more ones smaller $g$), 0 (same for all the nodes), 1 (fewer ones larger $g$)\n",
    "\n",
    "from collections import defaultdict\n",
    "from itertools import product\n",
    "import math\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from networkx.algorithms.graphical import is_graphical\n",
    "from networkx.utils.random_sequence import powerlaw_sequence\n",
    "import pickle as pkl\n",
    "\n",
    "n = 1_024\n",
    "size_seed = 2\n",
    "k = 10  # kronecker power\n",
    "p = 0.01\n",
    "R = 100_000\n",
    "g_list = np.arange(0, 0.11, 0.01)\n",
    "alpha_list = [-1, 0, 1]\n",
    "t = 1.5\n",
    "\n",
    "p_save = Path(\"KR\")\n",
    "p_save.mkdir(exist_ok=True)\n",
    "\n",
    "seed_matrix = np.array([[0.95, 0.63], [0.63, 0.32]])\n",
    "\n",
    "numOfOne2numNodes = dict()\n",
    "for i in range(k + 1):\n",
    "    # the number of length-k binary strings with i ones\n",
    "    numOfOne2numNodes[i] = math.comb(k, i)\n",
    "\n",
    "for g, alpha in product(g_list, alpha_list):\n",
    "    # first line: k, n_rounds, size of seed matrix\n",
    "    # (k+1) lines after that: each line is the alpha for nodes with that number of zeros in their binary representation\n",
    "    # the last lines: the seed matrix\n",
    "    \n",
    "    g_string = str(g).replace(\".\", \"p\")\n",
    "    alpha_string = str(alpha).replace(\".\", \"p\")\n",
    "    \n",
    "    weight_seq = [(i + 1) ** alpha for i in range(k + 1)]\n",
    "    sum_weight_raw = sum(w * numOfOne2numNodes[i] for i, w in enumerate(weight_seq))\n",
    "    target_g_sum = g * n\n",
    "    weight_seq = [w / sum_weight_raw * target_g_sum for w in weight_seq]\n",
    "    assert max(weight_seq) <= 1, f\"{max(weight_seq)}\"\n",
    "    \n",
    "    with open(p_save / f\"n{n}_p{p}_g{g_string}_alpha{alpha_string}_R{R}.txt\", \"w+\") as f:\n",
    "        f.write(f\"{k} {R} {size_seed}\\n\")\n",
    "        for w in weight_seq:\n",
    "            f.write(f\"{w}\\n\")\n",
    "        for row in seed_matrix:\n",
    "            for i_col, val in enumerate(row):\n",
    "                f.write(f\"{val}\")\n",
    "                if i_col != len(row) - 1:\n",
    "                    f.write(\" \")\n",
    "            f.write(\"\\n\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "junghun",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
